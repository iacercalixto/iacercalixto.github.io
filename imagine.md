---
layout: page
title: IMAGINE
---

**[IMAGINE][imagine]**: *Improving Multi-modal lAnguage Generation wIth world kNowledgE* is
a research project which main goal is to investigate how to incorporate **world knowledge** into
**vision &amp; language** tasks within **natural language generation**.
I am a [Marie Skwodówska-Curie Global Fellow][msca_gf].

I am spending ~2 years in New York University's [Courant Institute for Mathematical Sciences][nyu_cims]
where I will work with [Kyunghyun Cho][cho], followed by 3 months in Paris visiting [Antoine Bordes][abordes] in 
[Facebook Artificial Intelligence Research (FAIR)][fair].
I will finally return to the [Institute for Logic, Language and Computation (ILLC)][illc] in the University of Amsterdam,
where I will continue collaborating with [Raquel Fernández][raquel].

Concretely, I investigate how to:
* Gather world-knowledge (semi-)automatically from publicly available multi-modal knowledge bases.
* Learn representations for a knowledge base that encompasses both text and images.
* Integrate this knowledge into multi-modal language generation tasks, such as
multi-modal machine translation, visual question answering and image description generation.

Please [get in touch](mailto:iacer.calixto@nyu.edu) with you would like to collaborate on any of these research topics!

[msca_gf]: https://ec.europa.eu/research/mariecurieactions/actions/individual-fellowships_en
[cho]: http://www.kyunghyuncho.me/
[nyu_cims]: https://cims.nyu.edu/
[fair]: https://research.fb.com/category/facebook-ai-research/
[abordes]: https://research.fb.com/people/bordes-antoine/
[illc]: https://www.illc.uva.nl/
[raquel]: https://staff.science.uva.nl/r.fernandezrovira/
[imagine]: https://cordis.europa.eu/project/id/838188
